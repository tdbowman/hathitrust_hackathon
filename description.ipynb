{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANF2pBlvAhIP",
        "outputId": "853cfaf3-897b-4ade-c944-b7194299988c"
      },
      "outputs": [],
      "source": [
        "!pip install htrc-feature-reader\n",
        "# !pip install htrc\n",
        "# !pip install isbnlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iL1OZNB9v4E",
        "outputId": "2c86a104-f4e5-4f0d-e4cb-caaee03da3f1"
      },
      "outputs": [],
      "source": [
        "from lxml import etree\n",
        "import os\n",
        "from urllib.request import urlopen\n",
        "import json\n",
        "from htrc_features import *\n",
        "from htrc import workset, metadata\n",
        "import pandas as pd\n",
        "from lxml import etree\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "from isbnlib import mask, to_isbn10, is_isbn10, is_isbn13\n",
        "import re\n",
        "import linecache\n",
        "import time\n",
        "import json\n",
        "\n",
        "def get_link(link):\n",
        "    r = requests.get(link)\n",
        "    return(r)\n",
        "\n",
        "def get_htid(link):\n",
        "    r = get_link(link)\n",
        "    data = r.json()\n",
        "    if len(data[\"items\"]) > 0:\n",
        "      matched = True\n",
        "      htids = [(value['htid']) for value in data[\"items\"]]\n",
        "      year = [(value['publishDates']) for value in data[\"records\"].values()][0]\n",
        "      title = [(value['titles']) for value in data[\"records\"].values()][0]\n",
        "    else:\n",
        "      matched = False\n",
        "      htids = []\n",
        "      year = 0\n",
        "      title = \"\"\n",
        "    return(htids, year, title, matched)\n",
        "\n",
        "def get_subject(link):\n",
        "    r = get_link(link)\n",
        "    data = r.json()\n",
        "    result = [(value['marc-xml']) for value in data[\"records\"].values()][0]\n",
        "    result = result.replace('encoding=\"UTF-8\"', \"\")\n",
        "    root = etree.fromstring(result)\n",
        "    subject_list = []\n",
        "    for record in root:\n",
        "      fields = ['600', '610', '611', '630', '650', '651', '655']\n",
        "      subject_no = 0\n",
        "      for field in fields:\n",
        "        query = \"\".join(['{http://www.loc.gov/MARC21/slim}datafield[@tag=\"', field, '\"]'])\n",
        "        subjects = record.findall(query)\n",
        "        for item in subjects:\n",
        "          subfields = item.findall('{http://www.loc.gov/MARC21/slim}subfield')\n",
        "          Ind2 = item.get(\"ind2\")\n",
        "          if Ind2 == \"0\":\n",
        "            for s in subfields:\n",
        "              if s.get('code') == 'a':\n",
        "                  value = s.text\n",
        "                  subject_list.append(value)\n",
        "    return([subject_list, subject_no])\n",
        "\n",
        "\n",
        "# Open file and read line by line\n",
        "file1 = open('/content/classics_list.txt', 'r')\n",
        "\n",
        "count = sum( 1 for line in file1 )\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yeh4gr0ODPg",
        "outputId": "2ade45e7-41dd-459c-9061-88b38b195795"
      },
      "outputs": [],
      "source": [
        "data_summary = []\n",
        "htid_lists = []\n",
        "subject_lists = []\n",
        "\n",
        "for i in tqdm(range(1, count)):\n",
        "    # Get next line\n",
        "    url = linecache.getline('/content/classics_list.txt', i)\n",
        "    json_file_name = url.split(\"/\")[5].split(\".\")[0]\n",
        "\n",
        "    # if line is empty\n",
        "    # end of file is reached\n",
        "    if not url:\n",
        "        break\n",
        "\n",
        "    # store the response of URL\n",
        "    response = urlopen(url)\n",
        "\n",
        "    # storing the JSON response\n",
        "    # from url in data\n",
        "    data_json = json.loads(response.read())\n",
        "    if data_json['availability']['Open Library']:\n",
        "        open_lib_url = data_json['availability']['Open Library']\n",
        "        print(open_lib_url)\n",
        "\n",
        "        #https://openlibrary.org/search.json\n",
        "        new_open_lib_url = open_lib_url.replace('search?', 'search.json?')\n",
        "\n",
        "        r = requests.get(new_open_lib_url)\n",
        "        ol_data = r.json()\n",
        "        ol_filename = \"\".join(['./open_library_json/', json_file_name, '.json'])\n",
        "        try:\n",
        "          with open(ol_filename, 'w+') as file:\n",
        "            json.dump(ol_data, file)\n",
        "        except FileExistsError:\n",
        "          print(f\"The file '{file_path}' already exists.\")\n",
        "\n",
        "\n",
        "        # store the response of URL\n",
        "        response = urlopen(new_open_lib_url)\n",
        "        data_json = json.loads(response.read())\n",
        "\n",
        "        try:\n",
        "          rnumbers = data_json['docs'][0]['id_hathi_trust']\n",
        "        except:\n",
        "          rnumbers = []\n",
        "        try:\n",
        "          isbns = data_json['docs'][0]['isbn']\n",
        "        except:\n",
        "          isbns = []\n",
        "\n",
        "        rnumber_count = len(rnumbers)\n",
        "        isbn_count = len(isbns)\n",
        "\n",
        "        if rnumber_count > 0:\n",
        "          print(rnumbers[0])\n",
        "          link = \"\".join([\"https://catalog.hathitrust.org/api/volumes/full/recordnumber/\",\n",
        "                          rnumbers[0], \".json\"])\n",
        "        elif isbn_count > 0:\n",
        "          print(isbns[0])\n",
        "          link = \"\".join([\"https://catalog.hathitrust.org/api/volumes/full/isbn/\",\n",
        "                          isbns[0], \".json\"])\n",
        "        print(link)\n",
        "        htids = get_htid(link)\n",
        "\n",
        "        r = requests.get(link)\n",
        "        data = r.json()\n",
        "        ht_filename = \"\".join(['./hathitrust_json/', json_file_name, '.json'])\n",
        "        try:\n",
        "          with open(ht_filename, 'w+') as file:\n",
        "            json.dump(data, file)\n",
        "        except FileExistsError:\n",
        "          print(f\"The file '{file_path}' already exists.\")\n",
        "\n",
        "        data_summary.append({\n",
        "            \"osurl\":url,\n",
        "            \"ht_link\":link,\n",
        "            \"ht_matched\":htids[3],\n",
        "            \"htid_count\":len(htids[0]),\n",
        "            \"year\":htids[1],\n",
        "            'title':htids[2],\n",
        "            \"subject_no\":subjects[1]\n",
        "        })\n",
        "\n",
        "        if htids[3] == True:\n",
        "\n",
        "          subjects = get_subject(link)\n",
        "\n",
        "          for item in htids[0]:\n",
        "              htid_lists.append({\n",
        "                  \"osurl\":url,\n",
        "                  \"ht_link\":link,\n",
        "                  \"htid\":item\n",
        "              })\n",
        "          for item in subjects[0]:\n",
        "            subject_lists.append({\n",
        "                \"osurl\":url,\n",
        "                \"subject\":item\n",
        "            })\n",
        "\n",
        "\n",
        "        time.sleep(2)\n",
        "\n",
        "\n",
        "print(data_summary)\n",
        "print(htid_lists)\n",
        "print(subject_lists)\n",
        "\n",
        "file1.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP8r0B28MDVB",
        "outputId": "45e1cba5-69b4-4aff-84a2-688f24ef2ea9"
      },
      "outputs": [],
      "source": [
        "data_summary_df = pd.DataFrame(data_summary)\n",
        "\n",
        "print(len(data_summary))\n",
        "print(sum(data_summary_df['ht_matched']))\n",
        "print(len(htid_lists))\n",
        "print(len(subject_lists))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "b-9HxP4ZMjQw",
        "outputId": "208932a5-9738-46bc-e384-45ae8a105817"
      },
      "outputs": [],
      "source": [
        "data_summary_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kPDfR_wiMvTU",
        "outputId": "9fe6c11f-9ec8-438e-c72f-9353333d7460"
      },
      "outputs": [],
      "source": [
        "htid_df = pd.DataFrame(htid_lists)\n",
        "htid_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Io7Jvsw2sk7e",
        "outputId": "1b7bc20d-7045-42d8-c203-6e972f2693de"
      },
      "outputs": [],
      "source": [
        "subject_df = pd.DataFrame(subject_lists)\n",
        "subject_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "NeTv3HMVAXh5"
      },
      "outputs": [],
      "source": [
        "data_summary_df.to_csv(\"data_summary.csv\")\n",
        "htid_df.to_csv(\"htid_list.csv\")\n",
        "subject_df.to_csv(\"subject_list.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
